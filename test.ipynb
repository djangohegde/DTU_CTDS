{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mmh3\n",
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models import LdaMulticore, LdaModel\n",
    "from gensim import matutils as genmath, corpora, models\n",
    "from itertools import tee\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "DATA_SIZE=50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# eps = 0.8\n",
    "import scipy\n",
    "km = DBSCAN(eps=0.8, min_samples=1)\n",
    "my_data=[[1,1,1],[1,1,1],[1,1,1]]\n",
    "km.fit(my_data)\n",
    "print(km.labels_)\n",
    "# clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load the stored tfidf matrix '''\n",
    "with open(\"tfidf.pickle\", \"rb\") as handle:\n",
    "    tfidf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 169048)\t0.018580566882827637\n",
      "  (0, 168882)\t0.013244093918316288\n",
      "  (0, 167714)\t0.03225354540336226\n",
      "  (0, 167656)\t0.028558560278407658\n",
      "  (0, 166972)\t0.03555356732128179\n",
      "  (0, 166553)\t0.021625891460228926\n",
      "  (0, 166151)\t0.03178777735774555\n",
      "  (0, 165881)\t0.049929738482925735\n",
      "  (0, 165764)\t0.01731596439716341\n",
      "  (0, 165227)\t0.030223140274774025\n",
      "  (0, 164415)\t0.01720182241073771\n",
      "  (0, 164166)\t0.03166713656073263\n",
      "  (0, 163368)\t0.021763296580691666\n",
      "  (0, 162651)\t0.03295176670807751\n",
      "  (0, 162649)\t0.040576755070049667\n",
      "  (0, 162411)\t0.043916305667793525\n",
      "  (0, 162376)\t0.026239019725759417\n",
      "  (0, 162363)\t0.023767015736936008\n",
      "  (0, 162277)\t0.048820547824839335\n",
      "  (0, 160195)\t0.026056547751851452\n",
      "  (0, 159232)\t0.015609487520822654\n",
      "  (0, 157727)\t0.03644810640025725\n",
      "  (0, 157139)\t0.02506491940871817\n",
      "  (0, 157095)\t0.03933504059416844\n",
      "  (0, 155888)\t0.11360855478694346\n",
      "  :\t:\n",
      "  (0, 13084)\t0.03561243249263259\n",
      "  (0, 12967)\t0.03502110736722739\n",
      "  (0, 11426)\t0.030423665071382142\n",
      "  (0, 11419)\t0.04841932660230529\n",
      "  (0, 11418)\t0.055388502073048476\n",
      "  (0, 11414)\t0.05195133142564254\n",
      "  (0, 11257)\t0.03284948929113046\n",
      "  (0, 11254)\t0.038756740260905004\n",
      "  (0, 11252)\t0.05772608778395377\n",
      "  (0, 10714)\t0.04581455810753687\n",
      "  (0, 10712)\t0.03708020350102086\n",
      "  (0, 10523)\t0.015351533458249815\n",
      "  (0, 10454)\t0.02717512264395557\n",
      "  (0, 10151)\t0.050515889357185886\n",
      "  (0, 9351)\t0.019911265525491308\n",
      "  (0, 8472)\t0.026877075494223246\n",
      "  (0, 6514)\t0.031283685579957886\n",
      "  (0, 6291)\t0.031629427545948725\n",
      "  (0, 6028)\t0.23948996928420382\n",
      "  (0, 5577)\t0.02112394456632471\n",
      "  (0, 5455)\t0.03402107393358249\n",
      "  (0, 5209)\t0.024059870605052117\n",
      "  (0, 1692)\t0.024267856366798863\n",
      "  (0, 1672)\t0.01987313199780025\n",
      "  (0, 1651)\t0.02604114117613317\n"
     ]
    }
   ],
   "source": [
    "print(tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 173525)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input vector should be 1-D.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m km \u001b[39m=\u001b[39m DBSCAN(eps\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m, min_samples\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, metric\u001b[39m=\u001b[39mscipy\u001b[39m.\u001b[39mspatial\u001b[39m.\u001b[39mdistance\u001b[39m.\u001b[39mjaccard)\n\u001b[1;32m----> 4\u001b[0m km\u001b[39m.\u001b[39mfit(tfidf)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(km\u001b[39m.\u001b[39mlabels_)\n\u001b[0;32m      6\u001b[0m clusters \u001b[39m=\u001b[39m km\u001b[39m.\u001b[39mlabels_\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\hasee\\pyenvs\\comptools\\lib\\site-packages\\sklearn\\cluster\\_dbscan.py:406\u001b[0m, in \u001b[0;36mDBSCAN.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    404\u001b[0m neighbors_model\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m    405\u001b[0m \u001b[39m# This has worst case O(n^2) memory complexity\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m neighborhoods \u001b[39m=\u001b[39m neighbors_model\u001b[39m.\u001b[39;49mradius_neighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    408\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    409\u001b[0m     n_neighbors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mlen\u001b[39m(neighbors) \u001b[39mfor\u001b[39;00m neighbors \u001b[39min\u001b[39;00m neighborhoods])\n",
      "File \u001b[1;32mc:\\Users\\hasee\\pyenvs\\comptools\\lib\\site-packages\\sklearn\\neighbors\\_base.py:1149\u001b[0m, in \u001b[0;36mRadiusNeighborsMixin.radius_neighbors\u001b[1;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     results \u001b[39m=\u001b[39m neigh_dist, neigh_ind\n\u001b[0;32m   1148\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1149\u001b[0m     neigh_ind_list \u001b[39m=\u001b[39m \u001b[39msum\u001b[39;49m(chunked_results, [])\n\u001b[0;32m   1150\u001b[0m     results \u001b[39m=\u001b[39m _to_object_array(neigh_ind_list)\n\u001b[0;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m sort_results:\n",
      "File \u001b[1;32mc:\\Users\\hasee\\pyenvs\\comptools\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1850\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1849\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[1;32m-> 1850\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39mmetric, n_jobs\u001b[39m=\u001b[39mn_jobs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m   1851\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1852\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1854\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hasee\\pyenvs\\comptools\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2022\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m   2020\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m-> 2022\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\hasee\\pyenvs\\comptools\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1563\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1560\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1562\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 1563\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m   1565\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32mc:\\Users\\hasee\\pyenvs\\comptools\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1607\u001b[0m, in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1605\u001b[0m     iterator \u001b[39m=\u001b[39m itertools\u001b[39m.\u001b[39mproduct(\u001b[39mrange\u001b[39m(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), \u001b[39mrange\u001b[39m(Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]))\n\u001b[0;32m   1606\u001b[0m     \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m-> 1607\u001b[0m         out[i, j] \u001b[39m=\u001b[39m metric(X[i], Y[j], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m   1609\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\hasee\\pyenvs\\comptools\\lib\\site-packages\\scipy\\spatial\\distance.py:785\u001b[0m, in \u001b[0;36mjaccard\u001b[1;34m(u, v, w)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjaccard\u001b[39m(u, v, w\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    726\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m    Compute the Jaccard-Needham dissimilarity between two boolean 1-D arrays.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m \n\u001b[0;32m    784\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 785\u001b[0m     u \u001b[39m=\u001b[39m _validate_vector(u)\n\u001b[0;32m    786\u001b[0m     v \u001b[39m=\u001b[39m _validate_vector(v)\n\u001b[0;32m    788\u001b[0m     nonzero \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbitwise_or(u \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m, v \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hasee\\pyenvs\\comptools\\lib\\site-packages\\scipy\\spatial\\distance.py:301\u001b[0m, in \u001b[0;36m_validate_vector\u001b[1;34m(u, dtype)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[39mif\u001b[39;00m u\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m u\n\u001b[1;32m--> 301\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInput vector should be 1-D.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Input vector should be 1-D."
     ]
    }
   ],
   "source": [
    "# eps = 0.8\n",
    "import scipy\n",
    "km = DBSCAN(eps=0.8, min_samples=5, metric=scipy.spatial.distance.jaccard)\n",
    "km.fit(tfidf)\n",
    "print(km.labels_)\n",
    "clusters = km.labels_.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('comptools')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e991eec70dcdfedc5f1bcac3fae689529e9bd44f9e597bb7444204679111271f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
