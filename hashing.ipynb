{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import mmh3\n",
    "import numpy as np\n",
    "import itertools\n",
    "import collections\n",
    "import pandas as pd\n",
    "import more_itertools\n",
    "from itertools import tee\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "ROOT_DIR = os.path.abspath(os.curdir)\n",
    "#################### Utilities ######################\n",
    "#hashes a list of strings\n",
    "def listhash(l,seed):\n",
    "\tval = 0\n",
    "\tfor e in l:\n",
    "\t\tval = val ^ mmh3.hash(e, seed)\n",
    "\treturn val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our dataset and then put them into the dataframe \n",
    "# data = pd.read_csv(ROOT_DIR+\"\\\\data\\\\articles1.csv\")\n",
    "# data_content = data[\"content\"] #we are only interested in the content in each news\n",
    "########################\n",
    "docs = {} #dictionary mapping document id to document contents\n",
    "\n",
    "data = pd.read_csv(ROOT_DIR+\"\\\\data\\\\articles1.csv\")\n",
    "\n",
    "data_content = data[:50000][\"content\"]\n",
    "# docs = list(zip(data_content.tolist())) ## convert to tuple for starmap to work basically getting ['dfdf', 'dddd', 'sss'] => [('dfdf'), ('dddd'), ('sss')]\n",
    "# print(docs[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the document of stopwords \n",
    "stop = set(stopwords.words('english'))\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    This function takes as input a text on which several \n",
    "    NLTK algorithms will be applied in order to preprocess it\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove the punctuations, lower tokens and remove stopword\n",
    "    tokens = [word.lower() for word in tokens if word not in stop and len(word) > 2]\n",
    "   \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1={}\n",
    "for i in data_content.index:  \n",
    "    cleaned = clean(data_content[i])   \n",
    "    docs1[i] = str([' '.join(cleaned)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashed_lst_shingles2(q, doc):\n",
    "    \n",
    "    doc = doc.split(\" \")\n",
    "    lst_shingles=[]\n",
    "\n",
    "    lst_shingles = [doc[i:i+q] for i in range(0, len(doc), q-2)] # create list of shingles of length q\n",
    "\n",
    "    lst_shingles = [x for x in lst_shingles if len(x)==q] # remove shingles with length < q\n",
    "\n",
    "    return lst_shingles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Extension of standard pairwise function to 3-pairwise from the py standard lib'''\n",
    "def three_pairwise(iterable):\n",
    "    # pairwise('ABCDEFG') --> AB BC CD DE EF FG\n",
    "    # three_pairwise('ABCDEFG') --> ABC BCD CDE DEF EFG FG\n",
    "    a, b, c = tee(iterable, 3) ## Create three iterators\n",
    "    next(b, None) ## Advance the second\n",
    "    next(c, None) ## Advance the third\n",
    "    next(c, None) ## Advance the third once again. This ensures the third iterator starts at the third element and that we can create the 3-tuple\n",
    "    return zip(a, b, c) ### Zip everything (1 elem, 2 elem, and 3 elem) concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_clean = {}\n",
    "count = 1\n",
    "for i,k in docs1.items():\n",
    "  docs_clean[\"m{0}\".format(count)] = hashed_lst_shingles2(3,k)\n",
    "  count +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_perm = 100\n",
    "min_dict1 = {}\n",
    "count3 = 1\n",
    "for val in tqdm(docs_clean.values()):\n",
    "    m = MinHash(num_perm=num_perm)\n",
    "    for shingle in val:    \n",
    "      a= []\n",
    "      for i in shingle:\n",
    "        i.encode('utf8')\n",
    "        a.append(i)\n",
    "      data1 = str(['_'.join(a)])\n",
    "\n",
    "      m.update(data1.encode('utf8'))\n",
    "    min_dict1[\"m{}\".format(count3)] = m\n",
    "    count3+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "lsh = MinHashLSH(threshold=0.54, num_perm=num_perm)\n",
    "for key in tqdm(min_dict1.keys()):\n",
    "    lsh.insert(key,min_dict1[key]) # insert minhash data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def ror(n,rotations=1,width=32):\n",
    "    return (n >> rotations)|(n << (width - rotations)) & 0xFFFFFFFF\n",
    "    # return (2**width-1)&(n>>rotations|n<<(width-rotations))\n",
    "\n",
    "def gen_hashval(n):\n",
    "    return ror(n)^random.randint(0, 2**63-1)\n",
    "\n",
    "''' Extension of standard pairwise function to 3-pairwise from the py standard lib'''\n",
    "def three_pairwise(iterable):\n",
    "    # pairwise('ABCDEFG') --> AB BC CD DE EF FG\n",
    "    # three_pairwise('ABCDEFG') --> ABC BCD CDE DEF EFG FG\n",
    "    a, b, c = tee(iterable, 3) ## Create three iterators\n",
    "    next(b, None) ## Advance the second\n",
    "    next(c, None) ## Advance the third\n",
    "    next(c, None) ## Advance the third once again. This ensures the third iterator starts at the third element and that we can create the 3-tuple\n",
    "    return zip(a, b, c) ### Zip everything (1 elem, 2 elem, and 3 elem) concurrently.\n",
    "\n",
    "def hash_docs(doc, k=1000):\n",
    "    # three_tup=zip\n",
    "    lst_shingles_h=[]\n",
    "    # for doc in docs:\n",
    "    seed=1\n",
    "    three_tup=three_pairwise(doc.split(\" \"))\n",
    "\n",
    "    three_tup=list(three_tup)\n",
    "\n",
    "    three_tup=[elem for elem in three_tup if '' not in elem]\n",
    "    \n",
    "    # for t in three_tup:\n",
    "    #     if '' or ' ' in t:\n",
    "    #         print(\"single q\", t)\n",
    "    #     if \" \" or \"\" in t:\n",
    "    #         print(\"double \", t)\n",
    "\n",
    "    # print(set(three_tup))\n",
    "\n",
    "    # seeds = [seed+i for i in range(0,k)]\n",
    "    # ret_lst=[]\n",
    "    # for s in seeds:  \n",
    "    #     ret_lst.append(np.array(min([listhash(shingle, s) for shingle in three_tup], default=0)))  \n",
    "    # lens=[]\n",
    "    # my_lst=[]\n",
    "    # for shingle in three_tup:\n",
    "    #     my_lst.append(listhash(shingle, seed))\n",
    "    #     lens.append(len(my_lst))\n",
    "    # ret_lst.append(np.array(sorted(my_lst)[:k]))\n",
    "    # print(\"min len\", min(lens))\n",
    "    # ret_lst.append(np.array(sorted([listhash(shingle, seed) for shingle in three_tup])[:k]))\n",
    "    # print(\"min leng\", min(lens))\n",
    "    \n",
    "    # s_lst = sorted([listhash(shingle, seed) for shingle in three_tup])\n",
    "    # minhash_val = [listhash(shingle, seed) for shingle in three_tup]\n",
    "    '''compute other hash values based on this'''\n",
    "    # s_lst=[min([listhash(shingle, s) for shingle in three_tup], default=0) for s in seeds]\n",
    "    \n",
    "    # s_lst = [gen_hashval(minhash_val) for _ in range(k-1)]\n",
    "    # s_lst.append(minhash_val)\n",
    "    # s_lst=[]\n",
    "    # s_lst.append(min(minhash_val, default=0))\n",
    "    # for _ in range(k-1):\n",
    "    #     s_lst.append(min([gen_hashval(minval) for minval in minhash_val], default=0))\n",
    "\n",
    "    \n",
    "\n",
    "    # return np.array(s_lst)##[:k])#, len(s_lst)\n",
    "    return np.array(sorted([listhash(shingle, seed) for shingle in three_tup]))\n",
    "\n",
    "''' Returns document as a list of hashes'''\n",
    "'''\n",
    "Creates shingles of size q, removing shingles of size < q. Removes duplicates and hashes the result.\n",
    "'''\n",
    "def hashed_lst_shingles(my_docs):\n",
    "\n",
    "\n",
    "    hashed_docs = itertools.starmap(hash_docs, my_docs)\n",
    "    return hashed_docs\n",
    "\n",
    "# doc = \"You and me, we made a vow. For better or for worse. I can't believe you let me down\"\n",
    "# lst_shnigles = hashed_lst_shingles(3, doc)\n",
    "# print(lst_shnigles)\n",
    "# [['You', 'and', 'me,'], ['and', 'me,', 'we'], ['me,', 'we', 'made'], ['we', 'made', 'a'], ['made', 'a', 'vow.'], ['a', 'vow.', 'For'], ['vow.', 'For', 'better'], ['For', 'better', 'or'], ['better', 'or', 'for'], ['or', 'for', 'worse.'], ['for', 'worse.', 'I'], ['worse.', 'I', \"can't\"], ['I', \"can't\", 'believe'], [\"can't\", 'believe', 'you'], ['believe', 'you', 'let'], ['you', 'let', 'me'], ['let', 'me', 'down']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_lst=[1 for _ in range(100)]\n",
    "# a_lst=[2 for _ in range(100)]\n",
    "# res=[s_lst, a_lst]\n",
    "# np.stack(res).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinHashing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47521,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hasee\\AppData\\Local\\Temp\\ipykernel_4780\\799380711.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sig_m=np.array(hashed_shingles).T #5000x100 -> 100x5000\n"
     ]
    }
   ],
   "source": [
    "# test_docs=list(zip([\"You and me, we made a vow. For better or for worse. I can't believe you let me down\",\n",
    "# \"Time, space and state. Equal everything explanable.\",\n",
    "# \"You and me, we made a vow. For better or for worse. I can't believe you let me down\"]))\n",
    "hashed_shingles=hashed_lst_shingles(docs)\n",
    "# print(hash)\n",
    "hashed_shingles = list(hashed_shingles)\n",
    "hashed_shingles=[lst for lst in hashed_shingles if len(lst)>100]\n",
    "# hashed_shingles\n",
    "sig_m=np.array(hashed_shingles).T #5000x100 -> 100x5000\n",
    "print(sig_m.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(101, 47521)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens=min([len(x) for x in sig_m])\n",
    "print(lens)\n",
    "num_docs=sig_m.shape[0]\n",
    "for i in range(num_docs):\n",
    "    sig_m[i]=sig_m[i][:lens]\n",
    "sig_m=np.stack(sig_m).T\n",
    "sig_m.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_s=[]\n",
    "# for i in range(len(hashed_shingles)):\n",
    "#     my_s.append(hashed_shingles[i][1])\n",
    "# min(my_s)\n",
    "# # min(my_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSH implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Jaccard similarity'''\n",
    "def jaccard(s1, s2):\n",
    "    return len(s1 & s2) / len(s1 | s2)\n",
    "\n",
    "''' Implementation of LSH, dividing signature matrix into b band with r rows each'''\n",
    "def LSH(sig_m, b, r):\n",
    "    b=20\n",
    "    r=5\n",
    "    #b*r=num_hash_funcs\n",
    "\n",
    "    sim_hashes=[]\n",
    "    start=0\n",
    "    for i in range(b):\n",
    "        sim_hashes.append([listhash(col, seed=i) for col in sig_m[start:start+r,:].T])\n",
    "        start=i+r\n",
    "\n",
    "    return sim_hashes\n",
    "\n",
    "''' Find candidate pairs by checking to see if the hashes match.\n",
    "Then we check to see that the Jaccard similarity b/w each pair of docs is atleast t. If so, we consider it a candidate pair otherwise not '''\n",
    "def get_cand_pairs(sim_hashes, t):\n",
    "    cand_pairs=set()\n",
    "    for L in sim_hashes:\n",
    "        dups = collections.defaultdict(list)\n",
    "        for i, e in enumerate(L):\n",
    "            dups[e].append(i)\n",
    "        for _, v in sorted(dups.items()):\n",
    "            if len(v) >= 2:\n",
    "                cand_pairs.add(tuple(v))\n",
    "    cand_pairs=list(cand_pairs)\n",
    "    filtered_cand_pairs = [pair for pair in cand_pairs if (jaccard(set(sig_m[:, pair[0]]), set(sig_m[:, pair[1]])) > t)]\n",
    "    return filtered_cand_pairs\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=20\n",
    "r=5\n",
    "sim_hashes = LSH(sig_m, b=20, r=5)\n",
    "pairs=get_cand_pairs(sim_hashes, t=(1/b)**(1/r))\n",
    "len(pairs)\n",
    "# pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 47521)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(47381, 47422),\n",
       " (42957, 42965),\n",
       " (43171, 43321),\n",
       " (45465, 45663),\n",
       " (41980, 42274),\n",
       " (15705, 24350),\n",
       " (44545, 44740),\n",
       " (15236, 17272),\n",
       " (47032, 47046),\n",
       " (41620, 41633),\n",
       " (40643, 40763),\n",
       " (44249, 44435),\n",
       " (47384, 47518),\n",
       " (38982, 38995),\n",
       " (43546, 43845, 44135),\n",
       " (38765, 38816),\n",
       " (45476, 45664),\n",
       " (19563, 29213),\n",
       " (45790, 45997),\n",
       " (41101, 41187),\n",
       " (46647, 46703),\n",
       " (41786, 47187),\n",
       " (10977, 12007),\n",
       " (8035, 30924),\n",
       " (16620, 44519),\n",
       " (46331, 46346, 46704),\n",
       " (41731, 41980, 42274),\n",
       " (46330, 46345),\n",
       " (41619, 41632, 41979, 47031),\n",
       " (43546, 44135),\n",
       " (47380, 47421)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen using LSH, we find that documents 5 and 6 are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' (CNN) Film director David Lynch has confirmed he will no longer direct the revival of ”Twin Peaks”    a cult 1990s television show that was set to return in 2016. The offbeat TV series, created by Lynch and Mark Frost, featured a quirky FBI agent who went to the Pacific Northwest town of Twin Peaks to investigate the mysterious murder of a high school girl named Laura Palmer. The groundbreaking series is considered one of the most influential shows in television history. Lynch broke the news about his departure in a series of tweets, saying that the show’s third season will continue without him. He said he felt the network was not offering enough money to produce the show ”the way it needed to be done.” Lynch also wrote that he had personally called the actors over the weekend to let them know he would no longer be directing. Showtime Network, which will air the   comeback, released a statement saying they were ”saddened” by Lynch’s decision. ”We were saddened to read David Lynch’s statement today since we believed we were working towards solutions with David and his reps on the few remaining deal points,” read the statement. ”Showtime also loves the world of Twin Peaks and we continue to hold out hope that we can bring it back in all its glory with both of its extraordinary creators, David Lynch and Mark Frost, at its helm.” Showtime announced they would produce a third season in October last year.  Actor Kyle MacLachlan, who played the   FBI agent Dale Cooper in the original series, had confirmed he would reprise the lead role for the new season. ',)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[41116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' (CNN) Welcome to the first of April. It’s like Super Bowl Sunday for dad jokes, a day when we can all wake up, fire up the internet, and sigh a collective groan at the barrage of   pranks, tall tales and PR stunts conjured up by desperate media companies and junior brand creatives across the world. We’ll be here as long as we can take it today,   ourselves into oblivion as we catalog the good, the bad and the ugly of April Fools’ Day 2015. If you see anything worth mentioning, let us know in the comments.   eats his way across Google Maps, Google, the merry prankster of    corporate Web behemoths, has announced that you can now play   on Google Maps. Open a map in your browser, click the blue and black square in the bottom left of your screen, and before you know it, it’ll be lunchtime. Your UberBOAT is arriving, Why dart through the streets of your city in a Prius when you can take to the high seas? The dream has (very nearly) (not really) become reality in Thailand, where Uber will be piloting a program allowing users to hitch a ride on boats ”on the streets of Bangkok” ahead of the rainy season.  The cutting edge of technology, Samsung has announced this year’s   kitchen accessory    the Galaxy BLADE edge, ”the world’s first smart knife with smartphone capabilities,” according to the phonemaker. The   apparently features ”a   diamond edge, tough enough to cut through a lobster tail and sharp enough to slice though tender heirloom tomatoes.” It’s probably still not as good as an iPhone. James Corden gets punked, The new ”Late Late Show” host welcomes TV journalist Katie Couric, who enjoys a big laugh at his expense.  ”May the Force be with EU” Even scientists    scientists!    are getting in on the ”fun.” CERN researchers have used the Large Hadron Collider to smash together two of the world’s favorite things    Star Wars and April Fools’ pranks    in a press release confirming the discovery of The Force. CERN theorist Ben Kenobi has claimed that The Force is what binds the galaxy together, but   researcher Dave Vader (make it stop) dismissed the revelation with the quip ”Asteroids do not concern me.” Putin, Poroshenko to take this outside, Ukrainian President Petro Poroshenko has thrown down the gauntlet to Vladimir Putin, challenging the Russian leader to a   judo match to settle the future of eastern Ukraine, The Economist has reported. When reached for comment, a spokesman for Angela Merkel reportedly said: ”Bring it on.” Jeremy Clarkson’s ”  call”  It’s been a rough few weeks for Jeremy Clarkson, the former ”Top Gear” host who was sacked by the BBC for his ”fracas” with a producer.  Now, following what he has described as a ”dark night of the soul,” the former star of the world’s most popular car show has decided to dedicate his life to sustainable energy, throwing his weight behind The Guardian’s campaign for fossil fuel divestment. BMW’s Motor Mouth, BMW has announced the launch of a series mouth guards offering rugby players ”the same impact protection as our drivers.” The German car company says: ”The interior of the guard uses tyre tread technology and grips accordingly, while the BMW signature kidney grille lies between the front incisors acting as an elegant respiration vent.” Honda: The Selfie Edition, In perhaps the most inevitable development of the day, Honda has announced the     Selfie Edition. The hybrid combines two of American millenials’ favorite things    taking selfies and signing   expensive car leases that  will cripple their financial future for years to come. Honda says: ”With 10 cameras across the interior and exterior, the   Selfie Edition allows drivers to snap   while the car is in park.” A leg up on the competition, You and your   not already annoying enough? Why not get on the waiting list for the Selfie Shoes, the brainchild of something called Miz Mooz, which says it understands ”the importance of looking great without giving up the comfort our women    have come to love about our footwear.” ”Just insert your phone into the port at the front of either your right or left shoe, raise it to the perfect angle and click the internal button with a tap of your toe to take the photo.”  Finally, It was only a matter of time, really. If you live in the UK you will finally be able to carry Simon Cowell around with you in your pocket after the music mogul topped a poll of celebrities Brits would like to see on banknotes, The Sun has reported. The   ”American Idol” and ” ” judge will finally take his rightful place alongside the Queen, Charles Darwin and Adam Smith    other great British people who have their faces emblazoned on money.  #BransontoBranson, Virgin founder Richard Branson    never one to pass up a PR opportunity    got the party started a day early with his announcement that the British company’s U. S. operations would move to the heartland city of Branson, Missouri. He claimed Virgin would name its latest plane ”Jolene” in honor of the song by Dolly Parton    the town’s most famous celebrity    and that his water filtration business, Virgin Pure, would   the town’s water so he can ”enjoy the perfect cup of tea” whenever he’s in town. (It may actually) eat your heart out, Ever wanted to spend an evening with a vicious, occasionally   beast of the wild? Get yourself over to London’s first   hippo cafe, where you can dine with two baby pygmy hippos named George and Bungle    from Switzerland, no less    according to the Happy Hippo Cafe. ”Watch the hippos being fed at dusk by their handlers and then stay to take part in the nightly Hungry Hungry Hippo tournaments, while enjoying drinks and snacks,” the website says.  Bounce your way to loyalty points, Tesco has revolutionized the supermarket shopping experience once again (in a good way for once, hopefully) by introducing ”trampoline inspired bouncy aisles” to help you shorties reach the top shelves, Daisy O’Farllop (get it?) Director of Aisle Operations at Tesco, told the Retail Gazette. We’re actually quite into this idea.  Qatar to win Euro 2020?  Following up on their rather uncontroversial awarding of the 2022 World Cup, Qatar will be invited to qualify for the 2020 European football championships to help the country develop a footballing culture, The Daily Telegraph has reported. FIFA President Sepp Blatter has  personally proposed that the tiny Gulf state join qualification for Euro 2020 to provide European teams a chance to ”get to know” their 2022 hosts better. Tower of Pisa to be turned into hotel, The fine people of The Telegraph must have a lot of time on their hands, for it appears that Italian officials are taking heat over their plan to raise money by turning the Leaning Tower of Pisa into a luxury hotel. The proposal for the hotel    to be called 3. 99 Degrees    suggests each floor be turned into a single room with a   view named after a hero of the Italian renaissance, The Telegraph has reported. ’Hunchback University’ The Independent has reported that The University of Leicester will change its name to King Richard University to capitalize on the publicity surrounding the discovery and reburial of the bones of Richard III. The student bar will be renamed ”Carnage@Bosworth” and the name of administrative building will be changed to Hunchback House, according to the report. (Editor’s note: If you’d like some real Richard III news, head here). The rare April Fools’   April Fools’ Day pranks don’t always have to end with a groan    and for one woman in New Zealand, it actually ended with a new car.  A dealership in New Zealand put an ad in the paper claiming that the first person to come in and ”ask for Tom” would be able to swap their old car for a new BMW. Tiaana Marsh did just that, and . .. you can guess what happened from there.    Wait a second    why do we even do this? Ever wondered why you spent your entire day reading nonsense from the four corners of the Web? Here’s why, in two minutes. You’re welcome.',)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[41048]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('comptools')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e991eec70dcdfedc5f1bcac3fae689529e9bd44f9e597bb7444204679111271f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
