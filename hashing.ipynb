{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import mmh3\n",
    "import numpy as np\n",
    "import itertools\n",
    "import collections\n",
    "import pandas as pd\n",
    "import more_itertools\n",
    "from itertools import tee\n",
    "import re\n",
    "#################### Utilities ######################\n",
    "#hashes a list of strings\n",
    "def listhash(l,seed):\n",
    "\tval = 0\n",
    "\tfor e in l:\n",
    "\t\tval = val ^ mmh3.hash(e, seed)\n",
    "\treturn val \n",
    "\n",
    "################### Similarity ######################\n",
    "\n",
    "docs = {} #dictionary mapping document id to document contents\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\hasee\\Documents\\comptools\\DTU_CTDS\\data\\articles1.csv\")\n",
    "\n",
    "data1 = data[:1000]\n",
    "key = data1[\"Unnamed: 0\"]\n",
    "data2 = data1[\"content\"]\n",
    "docs = data2.to_dict()\n",
    "# docs = data2.tolist()\n",
    "# g_docs = data2.tolist()\n",
    "docs = list(zip(data2.tolist())) ## convert to tuple for starmap to work basically getting ['dfdf', 'dddd', 'sss'] => [('dfdf'), ('dddd'), ('sss')]\n",
    "# print(docs[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('WASHINGTON  —   Congressional Republicans have a new fear when it comes to their    health care lawsuit against the Obama administration: They might win. The incoming Trump administration could choose to no longer defend the executive branch against the suit, which challenges the administration’s authority to spend billions of dollars on health insurance subsidies for   and   Americans, handing House Republicans a big victory on    issues. But a sudden loss of the disputed subsidies could conceivably cause the health care program to implode, leaving millions of people without access to health insurance before Republicans have prepared a replacement. That could lead to chaos in the insurance market and spur a political backlash just as Republicans gain full control of the government. To stave off that outcome, Republicans could find themselves in the awkward position of appropriating huge sums to temporarily prop up the Obama health care law, angering conservative voters who have been demanding an end to the law for years. In another twist, Donald J. Trump’s administration, worried about preserving executive branch prerogatives, could choose to fight its Republican allies in the House on some central questions in the dispute. Eager to avoid an ugly political pileup, Republicans on Capitol Hill and the Trump transition team are gaming out how to handle the lawsuit, which, after the election, has been put in limbo until at least late February by the United States Court of Appeals for the District of Columbia Circuit. They are not yet ready to divulge their strategy. “Given that this pending litigation involves the Obama administration and Congress, it would be inappropriate to comment,” said Phillip J. Blando, a spokesman for the Trump transition effort. “Upon taking office, the Trump administration will evaluate this case and all related aspects of the Affordable Care Act. ” In a potentially   decision in 2015, Judge Rosemary M. Collyer ruled that House Republicans had the standing to sue the executive branch over a spending dispute and that the Obama administration had been distributing the health insurance subsidies, in violation of the Constitution, without approval from Congress. The Justice Department, confident that Judge Collyer’s decision would be reversed, quickly appealed, and the subsidies have remained in place during the appeal. In successfully seeking a temporary halt in the proceedings after Mr. Trump won, House Republicans last month told the court that they “and the  ’s transition team currently are discussing potential options for resolution of this matter, to take effect after the  ’s inauguration on Jan. 20, 2017. ” The suspension of the case, House lawyers said, will “provide the   and his future administration time to consider whether to continue prosecuting or to otherwise resolve this appeal. ” Republican leadership officials in the House acknowledge the possibility of “cascading effects” if the   payments, which have totaled an estimated $13 billion, are suddenly stopped. Insurers that receive the subsidies in exchange for paying    costs such as deductibles and   for eligible consumers could race to drop coverage since they would be losing money. Over all, the loss of the subsidies could destabilize the entire program and cause a lack of confidence that leads other insurers to seek a quick exit as well. Anticipating that the Trump administration might not be inclined to mount a vigorous fight against the House Republicans given the  ’s dim view of the health care law, a team of lawyers this month sought to intervene in the case on behalf of two participants in the health care program. In their request, the lawyers predicted that a deal between House Republicans and the new administration to dismiss or settle the case “will produce devastating consequences for the individuals who receive these reductions, as well as for the nation’s health insurance and health care systems generally. ” No matter what happens, House Republicans say, they want to prevail on two overarching concepts: the congressional power of the purse, and the right of Congress to sue the executive branch if it violates the Constitution regarding that spending power. House Republicans contend that Congress never appropriated the money for the subsidies, as required by the Constitution. In the suit, which was initially championed by John A. Boehner, the House speaker at the time, and later in House committee reports, Republicans asserted that the administration, desperate for the funding, had required the Treasury Department to provide it despite widespread internal skepticism that the spending was proper. The White House said that the spending was a permanent part of the law passed in 2010, and that no annual appropriation was required  —   even though the administration initially sought one. Just as important to House Republicans, Judge Collyer found that Congress had the standing to sue the White House on this issue  —   a ruling that many legal experts said was flawed  —   and they want that precedent to be set to restore congressional leverage over the executive branch. But on spending power and standing, the Trump administration may come under pressure from advocates of presidential authority to fight the House no matter their shared views on health care, since those precedents could have broad repercussions. It is a complicated set of dynamics illustrating how a quick legal victory for the House in the Trump era might come with costs that Republicans never anticipated when they took on the Obama White House.',)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt=[(1,2,3), (2,), (5,5,5,5,5)]\n",
    "rr=min(list(map(len, tt)))\n",
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Extension of standard pairwise function to 3-pairwise from the py standard lib'''\n",
    "def three_pairwise(iterable):\n",
    "    # pairwise('ABCDEFG') --> AB BC CD DE EF FG\n",
    "    # three_pairwise('ABCDEFG') --> ABC BCD CDE DEF EFG FG\n",
    "    a, b, c = tee(iterable, 3) ## Create three iterators\n",
    "    next(b, None) ## Advance the second\n",
    "    next(c, None) ## Advance the third\n",
    "    next(c, None) ## Advance the third once again. This ensures the third iterator starts at the third element and that we can create the 3-tuple\n",
    "    return zip(a, b, c) ### Zip everything (1 elem, 2 elem, and 3 elem) concurrently.\n",
    "\n",
    "def hash_docs(doc, k=50):\n",
    "    # three_tup=zip\n",
    "    lst_shingles_h=[]\n",
    "    # for doc in docs:\n",
    "    seed=1\n",
    "    three_tup=three_pairwise(doc.split(\" \"))\n",
    "\n",
    "    three_tup=list(three_tup)\n",
    "\n",
    "    three_tup=[elem for elem in three_tup if '' not in elem]\n",
    "    \n",
    "    # for t in three_tup:\n",
    "    #     if '' or ' ' in t:\n",
    "    #         print(\"single q\", t)\n",
    "    #     if \" \" or \"\" in t:\n",
    "    #         print(\"double \", t)\n",
    "\n",
    "    # print(set(three_tup))\n",
    "\n",
    "    # seeds = [seed+i for i in range(0,k)]\n",
    "    ret_lst=[]\n",
    "\n",
    "    # for s in seeds:  \n",
    "    ret_lst.append(np.array(sorted([listhash(shingle, seed) for shingle in three_tup])[:k]))\n",
    "    \n",
    "    return ret_lst\n",
    "\n",
    "''' Returns document as a list of hashes'''\n",
    "'''\n",
    "Creates shingles of size q, removing shingles of size < q. Removes duplicates and hashes the result.\n",
    "'''\n",
    "def hashed_lst_shingles(my_docs):\n",
    "\n",
    "\n",
    "    hashed_docs = itertools.starmap(hash_docs, my_docs)\n",
    "    return hashed_docs, len(my_docs)\n",
    "\n",
    "# doc = \"You and me, we made a vow. For better or for worse. I can't believe you let me down\"\n",
    "# lst_shnigles = hashed_lst_shingles(3, doc)\n",
    "# print(lst_shnigles)\n",
    "# [['You', 'and', 'me,'], ['and', 'me,', 'we'], ['me,', 'we', 'made'], ['we', 'made', 'a'], ['made', 'a', 'vow.'], ['a', 'vow.', 'For'], ['vow.', 'For', 'better'], ['For', 'better', 'or'], ['better', 'or', 'for'], ['or', 'for', 'worse.'], ['for', 'worse.', 'I'], ['worse.', 'I', \"can't\"], ['I', \"can't\", 'believe'], [\"can't\", 'believe', 'you'], ['believe', 'you', 'let'], ['you', 'let', 'me'], ['let', 'me', 'down']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinHashing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def minhash(shingles, seed):\n",
    "#     # print(\"what is this>\")\n",
    "#     # print(shingles)\n",
    "#     return min([listhash(shingle, seed) for shingle in shingles])\n",
    "\n",
    "# def minhash2(shingles, seed, k):\n",
    "#     minhashes=[]\n",
    "#     seeds = [seed+i for i in range(0,k)]\n",
    "#     for s in seeds:\n",
    "#         minhashes.append(minhash(shingles, s))\n",
    "    \n",
    "#     return minhashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def signatures(my_shingles, num_hash, seed=1):\n",
    "#     # lst_shingles = ex2.shingle(q=shingle_size, in_str=in_str)\n",
    "#     sig_lst=[]\n",
    "#     for i, shingle in enumerate(my_shingles):\n",
    "#         sig = minhash2(shingles=shingle, seed=seed, k=num_hash)\n",
    "#         sig_lst[i] = sig\n",
    "\n",
    "#     return sig_lst\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sss (1, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hasee\\AppData\\Local\\Temp\\ipykernel_12596\\1348849060.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sig_m=np.array(hashed_shingles).T\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [226], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m# sig_m = np.array(list(hashed_shingles)).T\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msss\u001b[39m\u001b[39m\"\u001b[39m,sig_m\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 10\u001b[0m sig_m\u001b[39m=\u001b[39msig_m\u001b[39m.\u001b[39mreshape(sig_m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], sig_m\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])\n\u001b[0;32m     11\u001b[0m sig_m\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# test_docs=list(zip([\"You and me, we made a vow. For better or for worse. I can't believe you let me down\",\n",
    "# \"Time, space and state. Equal everything explanable.\",\n",
    "# \"You and me, we made a vow. For better or for worse. I can't believe you let me down\"]))\n",
    "hashed_shingles, my_len=hashed_lst_shingles(docs)\n",
    "hashed_shingles = list(hashed_shingles)\n",
    "# nnn=np.stack(hashed_shingles)\n",
    "sig_m=np.array(hashed_shingles).T\n",
    "# sig_m = np.array(list(hashed_shingles)).T\n",
    "print(\"sss\",sig_m.shape)\n",
    "sig_m=sig_m.reshape(sig_m.shape[0], sig_m.shape[2])\n",
    "sig_m.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From results of sig matrix above, documents 1 and 3 are very similar (similar hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Jaccard similarity'''\n",
    "def jaccard(s1, s2):\n",
    "    return len(s1 & s2) / len(s1 | s2)\n",
    "\n",
    "# score = jaccard(set(sig_m[:, 5]), set(sig_m[:, 6])) # finding similarity b/w documents 5 and 6. remember00palm.txt and remembermeorholy00palm.txt\n",
    "\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that docs 5 and 6 are quite similar (0.61)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSH implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Implementation of LSH, dividing signature matrix into b band with r rows each'''\n",
    "def LSH(sig_m, b, r):\n",
    "    b=20\n",
    "    r=5\n",
    "    #b*r=num_hash_funcs\n",
    "\n",
    "    sim_hashes=[]\n",
    "    start=0\n",
    "    for i in range(b):\n",
    "        sim_hashes.append([listhash(col, seed=i) for col in sig_m[start:start+r,:].T])\n",
    "        start=i+r\n",
    "\n",
    "    return sim_hashes\n",
    "\n",
    "''' Find candidate pairs by checking to see if the hashes match.\n",
    "Then we check to see that the Jaccard similarity b/w each pair of docs is atleast t. If so, we consider it a candidate pair otherwise not '''\n",
    "def get_cand_pairs(sim_hashes, t):\n",
    "    cand_pairs=set()\n",
    "    for L in sim_hashes:\n",
    "        dups = collections.defaultdict(list)\n",
    "        for i, e in enumerate(L):\n",
    "            dups[e].append(i)\n",
    "        for k, v in sorted(dups.items()):\n",
    "            if len(v) >= 2:\n",
    "                cand_pairs.add(tuple(v))\n",
    "                # print(k, v)\n",
    "    cand_pairs=list(cand_pairs)\n",
    "    filtered_cand_pairs = [pair for pair in cand_pairs if (jaccard(set(sig_m[:, pair[0]]), set(sig_m[:, pair[1]])) > t)]\n",
    "    return filtered_cand_pairs\n",
    "    # return cand_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1977450224, -1474616243, -1358494162, -1349483768, -1284103952,\n",
       "       -1063952611,  -266913181,   307140698,   399421633,   678722671,\n",
       "         727187198,   790074072,   979649597,  1012655871,  1273310172,\n",
       "        1657204410,  2064897588])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=20\n",
    "r=5\n",
    "sim_hashes = LSH(sig_m, b=20, r=5)\n",
    "pairs=get_cand_pairs(sim_hashes, t=(1/b)**(1/r))\n",
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen using LSH, we find that documents 5 and 6 are similar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('comptools')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e991eec70dcdfedc5f1bcac3fae689529e9bd44f9e597bb7444204679111271f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
